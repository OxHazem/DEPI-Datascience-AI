{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ML2ZARBRsU0g",
    "papermill": {
     "duration": 0.026224,
     "end_time": "2020-10-15T19:37:03.373469",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.347245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Let’s scrape the data from the web using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42v-u2qzsRS-",
    "papermill": {
     "duration": 0.024495,
     "end_time": "2020-10-15T19:37:03.423525",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.399030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/pluralsight/guides/master/images/310d6edd-b569-408a-a61d-f6d9a9a9eb61.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fq6AxmBYsXrT",
    "papermill": {
     "duration": 0.023776,
     "end_time": "2020-10-15T19:37:03.472654",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.448878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Today we will be scraping “[Rate My Professor](https://www.ratemyprofessors.com/)” website. A little insight about Rate My Professor website, it is a website that contains a rating of school, professors and universities. You can search for any professor or school and get their ratings before taking or joining to their courses. It’s a handy feature which helps to know more about your professor or the university that you want to join. In this tutorial, we shall see how to scrape and to extract a specific professor’s tag. I warn you guys this is not illegal but the mass scraping of data from the website can lead your IP address being blocked. Just do it once or twice, but don’t just foolishly put it in a loop and try to put request inside the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teMB0jnMELj2",
    "papermill": {
     "duration": 0.02371,
     "end_time": "2020-10-15T19:37:03.520622",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.496912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![alt text](https://i.kym-cdn.com/entries/icons/original/000/026/575/5ac80d20dfc1e.image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TESiRp8VE44M",
    "papermill": {
     "duration": 0.023982,
     "end_time": "2020-10-15T19:37:03.568489",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.544507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**What is Web Scraping ?**\n",
    "\n",
    "Web Scraping (also termed as Scraping, Data Extraction, Data Harvesting, etc.) is a technique used to extract data from the websites. Sometimes web scraping can be very useful wherein we can get the data that we are looking for straight from the web, but sometimes it a bad way to do it, because it’s like stealing the precious data from the website without their permission, but limit your scraping process to once or twice so that this can avoid you from falling in trouble.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkHyOX1psqcH",
    "papermill": {
     "duration": 0.024283,
     "end_time": "2020-10-15T19:37:03.618390",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.594107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The most useful libraries required for web scraping are:\n",
    "\n",
    "1. [Beautiful Soup.](https://www.crummy.com/software/BeautifulSoup/bs4/doc/?source=post_page---------------------------)\n",
    "\n",
    "2. [Requests.](https://2.python-requests.org/en/master/?source=post_page---------------------------)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kY2HX-VftA4T",
    "papermill": {
     "duration": 0.023534,
     "end_time": "2020-10-15T19:37:03.666078",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.642544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## These are the steps that we would be following throughout this tutorial:\n",
    "\n",
    "1. Importing the required libraries.\n",
    "\n",
    "2. Getting the URL and storing it in a variable.\n",
    "\n",
    "3. Making a request to the website using the requests library.\n",
    "\n",
    "4. Using the Beautiful Soup library to get the HTML (raw) data from the website.\n",
    "\n",
    "5. Using soup.findAll method to get the respected tag that we are looking for.\n",
    "\n",
    "6. Removing all the HTML tags and converting it to a plain text format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAe3tdqstNU0",
    "papermill": {
     "duration": 0.023547,
     "end_time": "2020-10-15T19:37:03.713629",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.690082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You might be wondering what tags to extract, well in the Rate My Professor website every professor will have his/her respected tags such as (hilarious, heavy homework, study hard or fail, etc.), we will just try to extra these tags in this tutorials as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Sy58JjEtuG5",
    "papermill": {
     "duration": 0.024587,
     "end_time": "2020-10-15T19:37:03.762058",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.737471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![alt text](http://i64.tinypic.com/35klron.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxNY9FqDt5pN",
    "papermill": {
     "duration": 0.023733,
     "end_time": "2020-10-15T19:37:03.810277",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.786544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before we begin make sure to scrape the data at a slow pace, and you can also use a VPN service to get a different IP address, this prevents your IP address from banning, but I hope you guys will follow the instructions. Here is an [article](https://hackernoon.com/how-to-scrape-a-website-without-getting-blacklisted-271a605a0d94?source=post_page---------------------------) that will let you know how to scrape a website without getting blacklisted. One important thing in this tutorial there is no point of me explaining each and every line of code, which is not needed here because python code is self-explanatory. However, I will try not to confuse you, and make things clear in an easy way. So I wrote this tutorial in such a way that everybody can understand irrespective of their programming background. Moreover, the entire source code can be found in my GitHub. There might be numerous tutorials available on the internet, but this tutorial is easy to understand because I have tried to explain the code as much as possible, some parts are a mechanical process, wherein you just have to follow them, just let me know if you have any doubt in the comments section down below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e4KeKhit_TD",
    "papermill": {
     "duration": 0.024178,
     "end_time": "2020-10-15T19:37:03.858863",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.834685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let’s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QMkozcWJi4j",
    "papermill": {
     "duration": 0.023827,
     "end_time": "2020-10-15T19:37:03.906675",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.882848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Step 1: Importing the required libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qte8uE9SuFA1",
    "papermill": {
     "duration": 0.024377,
     "end_time": "2020-10-15T19:37:03.955111",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.930734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us import few important libraries such as Requests and BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T19:37:04.009649Z",
     "iopub.status.busy": "2020-10-15T19:37:04.008706Z",
     "iopub.status.idle": "2020-10-15T19:37:04.310213Z",
     "shell.execute_reply": "2020-10-15T19:37:04.309376Z"
    },
    "id": "bQIL3UbWh3II",
    "papermill": {
     "duration": 0.331509,
     "end_time": "2020-10-15T19:37:04.310357",
     "exception": false,
     "start_time": "2020-10-15T19:37:03.978848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6GDKT8Gu-ov",
    "papermill": {
     "duration": 0.023348,
     "end_time": "2020-10-15T19:37:04.358125",
     "exception": false,
     "start_time": "2020-10-15T19:37:04.334777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81N6kDoxM4ke",
    "papermill": {
     "duration": 0.023474,
     "end_time": "2020-10-15T19:37:04.405560",
     "exception": false,
     "start_time": "2020-10-15T19:37:04.382086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Step 2: Getting the URL and storing it in a variable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02ugpc6OuK0U",
    "papermill": {
     "duration": 0.023784,
     "end_time": "2020-10-15T19:37:04.453103",
     "exception": false,
     "start_time": "2020-10-15T19:37:04.429319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us store the URL of the professor in the variable named “url”. The URL of the website can be found here: “[Rate My Professor](https://www.ratemyprofessors.com/ShowRatings.jsp?tid=1986099&source=post_page---------------------------)”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T19:37:04.507237Z",
     "iopub.status.busy": "2020-10-15T19:37:04.506258Z",
     "iopub.status.idle": "2020-10-15T19:37:04.509794Z",
     "shell.execute_reply": "2020-10-15T19:37:04.509031Z"
    },
    "id": "aadHoY69jEWI",
    "papermill": {
     "duration": 0.032349,
     "end_time": "2020-10-15T19:37:04.509930",
     "exception": false,
     "start_time": "2020-10-15T19:37:04.477581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://www.ratemyprofessors.com/ShowRatings.jsp?tid=941931'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6-3kmHIu9nV",
    "papermill": {
     "duration": 0.023638,
     "end_time": "2020-10-15T19:37:04.557582",
     "exception": false,
     "start_time": "2020-10-15T19:37:04.533944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KP2pzOgWNG4u",
    "papermill": {
     "duration": 0.023695,
     "end_time": "2020-10-15T19:37:04.605305",
     "exception": false,
     "start_time": "2020-10-15T19:37:04.581610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "**Step 3: Making a request to the website using the requests library.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fHhlDOQuTB4",
    "papermill": {
     "duration": 0.023723,
     "end_time": "2020-10-15T19:37:04.653061",
     "exception": false,
     "start_time": "2020-10-15T19:37:04.629338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we use the requests library by passing “url” as a parameter, be careful don’t run this multiple times. If you get like Response 200 then its success, if you get something else then there is something wrong with maybe the code or your browser I don’t know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T19:37:04.707766Z",
     "iopub.status.busy": "2020-10-15T19:37:04.706984Z",
     "iopub.status.idle": "2020-10-15T19:37:06.566380Z",
     "shell.execute_reply": "2020-10-15T19:37:06.565609Z"
    },
    "id": "r0wPh55bjJrp",
    "papermill": {
     "duration": 1.889536,
     "end_time": "2020-10-15T19:37:06.566541",
     "exception": false,
     "start_time": "2020-10-15T19:37:04.677005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T19:37:06.623506Z",
     "iopub.status.busy": "2020-10-15T19:37:06.622318Z",
     "iopub.status.idle": "2020-10-15T19:37:06.626496Z",
     "shell.execute_reply": "2020-10-15T19:37:06.627064Z"
    },
    "id": "yY1A4nnijnfT",
    "outputId": "0e696a12-81ab-4f85-ef26-2af358ab444f",
    "papermill": {
     "duration": 0.036078,
     "end_time": "2020-10-15T19:37:06.627216",
     "exception": false,
     "start_time": "2020-10-15T19:37:06.591138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [503]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXK-919ku8h5",
    "papermill": {
     "duration": 0.024651,
     "end_time": "2020-10-15T19:37:06.677125",
     "exception": false,
     "start_time": "2020-10-15T19:37:06.652474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9-SmRvFNtcz",
    "papermill": {
     "duration": 0.024703,
     "end_time": "2020-10-15T19:37:06.726742",
     "exception": false,
     "start_time": "2020-10-15T19:37:06.702039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Step 4: Using the Beautiful Soup library to get the HTML (raw) data from the website.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqwmHpL6uYBt",
    "papermill": {
     "duration": 0.025053,
     "end_time": "2020-10-15T19:37:06.776759",
     "exception": false,
     "start_time": "2020-10-15T19:37:06.751706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we use the BeautifulSoup by passing the page.text as a parameter and using the HTML parser. You can try to print the soup, but printing the soup doesn’t give you the answer, rather it contains huge chunks of HTML data, so I decided not to show it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T19:37:06.840233Z",
     "iopub.status.busy": "2020-10-15T19:37:06.835474Z",
     "iopub.status.idle": "2020-10-15T19:37:06.925492Z",
     "shell.execute_reply": "2020-10-15T19:37:06.926138Z"
    },
    "id": "B32OMv-4j1BJ",
    "papermill": {
     "duration": 0.124756,
     "end_time": "2020-10-15T19:37:06.926306",
     "exception": false,
     "start_time": "2020-10-15T19:37:06.801550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnS9Q0nGOJAa",
    "papermill": {
     "duration": 0.025138,
     "end_time": "2020-10-15T19:37:06.976496",
     "exception": false,
     "start_time": "2020-10-15T19:37:06.951358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Step 5: Using soup.findAll method to get the respected tag that we are looking for.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7o3aamYtucnr",
    "papermill": {
     "duration": 0.024791,
     "end_time": "2020-10-15T19:37:07.027682",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.002891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here is the place where you shall add the tags that you are looking for, to get the tag name all you have to do is to right click on the respected tag or click Ctrl-Shift-I on the tag in the webpage, then a page with selected tag will open for you to your right-hand side as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5kH-6oVurgW",
    "papermill": {
     "duration": 0.024881,
     "end_time": "2020-10-15T19:37:07.077941",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.053060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can then copy the HTML tag and class if any, and then place it inside the soup.findAll method. In this case, the HTML tag is “span” and class is “tag-box-choosetags”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T19:37:07.150716Z",
     "iopub.status.busy": "2020-10-15T19:37:07.142680Z",
     "iopub.status.idle": "2020-10-15T19:37:07.156211Z",
     "shell.execute_reply": "2020-10-15T19:37:07.155496Z"
    },
    "id": "mOZlRX52lyQK",
    "outputId": "59d32d6d-9122-43e7-ef0e-5d69da1222ce",
    "papermill": {
     "duration": 0.053198,
     "end_time": "2020-10-15T19:37:07.156335",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.103137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"Tag-bs9vf4-0 hHOVKF\">Tough grader</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Lots of homework</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Skip class? You won't pass.</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Beware of pop quizzes</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Caring</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Get ready to read</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Participation matters</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Hilarious</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Graded by few things</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Tough grader</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Skip class? You won't pass.</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Test heavy</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Tough grader</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Respected</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Skip class? You won't pass.</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Caring</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Respected</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Hilarious</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Amazing lectures</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Respected</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">TEST HEAVY</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Amazing lectures</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Inspirational</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Hilarious</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Caring</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Tough Grader</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Skip class? You won't pass.</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">LOTS OF HOMEWORK</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Tough Grader</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Skip class? You won't pass.</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">LOTS OF HOMEWORK</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Respected</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Tough Grader</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Skip class? You won't pass.</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">BEWARE OF POP QUIZZES</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">LOTS OF HOMEWORK</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">GROUP PROJECTS</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Tough Grader</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Skip class? You won't pass.</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Caring</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">GRADED BY FEW THINGS</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">GROUP PROJECTS</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">LECTURE HEAVY</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Skip class? You won't pass.</span>,\n",
       " <span class=\"Tag-bs9vf4-0 hHOVKF\">Caring</span>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proftags = soup.findAll(\"span\", {\"class\": \"Tag-bs9vf4-0\" })\n",
    "proftags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2edHSXyu5z1",
    "papermill": {
     "duration": 0.025524,
     "end_time": "2020-10-15T19:37:07.208175",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.182651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SOauojTRxgh",
    "papermill": {
     "duration": 0.025628,
     "end_time": "2020-10-15T19:37:07.259522",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.233894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Step 6: Removing all the HTML tags and converting it to a plain text format.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9RGUKtHuwU0",
    "papermill": {
     "duration": 0.025403,
     "end_time": "2020-10-15T19:37:07.310937",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.285534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we remove all the HTML tags and convert it to a text format, this can be done with the help of get_text method placed inside a for loop. This converts the HTML into the text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-15T19:37:07.370702Z",
     "iopub.status.busy": "2020-10-15T19:37:07.369830Z",
     "iopub.status.idle": "2020-10-15T19:37:07.374225Z",
     "shell.execute_reply": "2020-10-15T19:37:07.375620Z"
    },
    "id": "m6xBHR-fmJAD",
    "outputId": "6ef8ce58-0113-4100-974f-a1c2bbc313e0",
    "papermill": {
     "duration": 0.038504,
     "end_time": "2020-10-15T19:37:07.375875",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.337371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tough grader\n",
      "Lots of homework\n",
      "Skip class? You won't pass.\n",
      "Beware of pop quizzes\n",
      "Caring\n",
      "Get ready to read\n",
      "Participation matters\n",
      "Hilarious\n",
      "Graded by few things\n",
      "Tough grader\n",
      "Skip class? You won't pass.\n",
      "Test heavy\n",
      "Tough grader\n",
      "Respected\n",
      "Skip class? You won't pass.\n",
      "Caring\n",
      "Respected\n",
      "Hilarious\n",
      "Amazing lectures\n",
      "Respected\n",
      "TEST HEAVY\n",
      "Amazing lectures\n",
      "Inspirational\n",
      "Hilarious\n",
      "Caring\n",
      "Tough Grader\n",
      "Skip class? You won't pass.\n",
      "LOTS OF HOMEWORK\n",
      "Tough Grader\n",
      "Skip class? You won't pass.\n",
      "LOTS OF HOMEWORK\n",
      "Respected\n",
      "Tough Grader\n",
      "Skip class? You won't pass.\n",
      "BEWARE OF POP QUIZZES\n",
      "LOTS OF HOMEWORK\n",
      "GROUP PROJECTS\n",
      "Tough Grader\n",
      "Skip class? You won't pass.\n",
      "Caring\n",
      "GRADED BY FEW THINGS\n",
      "GROUP PROJECTS\n",
      "LECTURE HEAVY\n",
      "Skip class? You won't pass.\n",
      "Caring\n"
     ]
    }
   ],
   "source": [
    "for mytag in proftags:\n",
    "    print(mytag.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgJ12-z9Sl9p",
    "papermill": {
     "duration": 0.026087,
     "end_time": "2020-10-15T19:37:07.430857",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.404770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Hence we got the above information that we were looking for. We got all the tags of the professor. This is how we scrape the data from the internet by using Requests and Beautiful Soup libraries. To be frank this is my professor who teaches the subject “Data Science”. He is one of the best professors in the entire university. I like his teaching and his style.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9XLrULOu1aq",
    "papermill": {
     "duration": 0.026176,
     "end_time": "2020-10-15T19:37:07.483968",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.457792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Thank you guys for spending your time reading my tutorial, stay tuned for more updates. Let me know what is your opinion about this tutorial in the comment section below. Also if you have any doubts regarding the code, comment section is all yours. Have a nice day.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVYBkYgbu4cm",
    "papermill": {
     "duration": 0.026002,
     "end_time": "2020-10-15T19:37:07.536397",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.510395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.026388,
     "end_time": "2020-10-15T19:37:07.590497",
     "exception": false,
     "start_time": "2020-10-15T19:37:07.564109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "papermill": {
   "duration": 9.157395,
   "end_time": "2020-10-15T19:37:07.726745",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-15T19:36:58.569350",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
